{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nebyathhailu/movie-recommendation-agent/blob/main/Movie_Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulECGDLoesnJ"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install pandas transformers torch langchain langchain-community nltk chromadb tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5poLSoFzkTMs"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8wkSEG9GpUD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from typing import List\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import os\n",
        "import nltk\n",
        "\n",
        "# LangChain components\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# nltk for lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Transformers for embeddings and LLM\n",
        "from transformers import AutoTokenizer, AutoModel, pipeline\n",
        "\n",
        "# ChromaDB for vector storage\n",
        "import chromadb\n",
        "from chromadb.config import Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6uYKGoeIWZe"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset_path = '/content/drive/MyDrive/imdb_top_1000.csv'\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(f\"Dataset not found at {dataset_path}. Please upload it.\")\n",
        "\n",
        "movies = pd.read_csv(dataset_path)\n",
        "movies['movie_id'] = movies.index.astype(str)\n",
        "print(f\"Loaded {len(movies)} movies from the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NURbdMqnJMZT"
      },
      "outputs": [],
      "source": [
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to lemmatize text\n",
        "def lemmatize_text(text):\n",
        "    \"\"\"Tokenizes, lemmatizes, and joins text back into a string.\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return \" \".join(lemmatized_tokens)\n",
        "\n",
        "print(\"\\nStep 2: Preprocessing, Lemmatizing, and Chunking Overviews...\")\n",
        "\n",
        "# Download the punkt_tab resource\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Apply lemmatization to the 'Overview' column\n",
        "movies['Lemmatized_Overview'] = movies['Overview'].apply(lemmatize_text)\n",
        "\n",
        "# Initialize the text splitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "\n",
        "# Prepare lists for our chunked data\n",
        "chunked_texts = []\n",
        "chunked_ids = []\n",
        "chunked_metadatas = []\n",
        "\n",
        "for index, row in movies.iterrows():\n",
        "    lemmatized_overview = row['Lemmatized_Overview']\n",
        "    if not lemmatized_overview:\n",
        "        continue\n",
        "\n",
        "    chunks = text_splitter.split_text(lemmatized_overview)\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_id = f\"{row['movie_id']}_chunk_{i}\"\n",
        "\n",
        "        # Store the original, non-lemmatized metadata for explanations\n",
        "        metadata = {\n",
        "            \"movie_id\": row['movie_id'],\n",
        "            \"Series_Title\": row['Series_Title'],\n",
        "            \"Director\": row['Director'],\n",
        "            \"Genre\": row['Genre'],\n",
        "            \"IMDB_Rating\": row['IMDB_Rating'],\n",
        "            \"Meta_score\": row['Meta_score'],\n",
        "            \"No_of_Votes\": row['No_of_Votes'],\n",
        "            \"Released_Year\": row['Released_Year'],\n",
        "            \"Full_MetaText\": f\"Title: {row['Series_Title']}\\nDirector: {row['Director']}\\nGenre: {row['Genre']}\\nPlot: {row['Overview']}\\nStars: {row['Star1']}, {row['Star2']}\\nYear: {row['Released_Year']}\\nRating: {row['IMDB_Rating']}\"\n",
        "        }\n",
        "\n",
        "        chunked_texts.append(chunk)\n",
        "        chunked_ids.append(chunk_id)\n",
        "        chunked_metadatas.append(metadata)\n",
        "\n",
        "print(f\"Created {len(chunked_texts)} lemmatized chunks from {len(movies)} movies.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aXwqJ8jsLEQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a4bffd-96f8-4f32-8317-b10079ff4b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding model loaded on device: cuda\n",
            "Using existing lemmatized collection with 1000 items.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- STEP 3: EMBEDDINGS AND CHROMADB STORAGE ---\n",
        "\n",
        "# Define the E5 Embedding Wrapper (no changes needed here)\n",
        "class E5EmbeddingWrapper:\n",
        "    def __init__(self, model_name=\"intfloat/multilingual-e5-small\"):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "        print(f\"Embedding model loaded on device: {self.device}\")\n",
        "\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        inputs = self.tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(self.device)\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        return outputs.last_hidden_state[:, 0, :].cpu().numpy().tolist()[0]\n",
        "\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        return [self.embed_query(text) for text in texts]\n",
        "\n",
        "    def __call__(self, text: str) -> List[float]:\n",
        "        return self.embed_query(text)\n",
        "\n",
        "# Initialize the embedding model\n",
        "print(\"\\nStep 3: Initializing Embedding Model and Connecting to ChromaDB...\")\n",
        "embeddings = E5EmbeddingWrapper()\n",
        "\n",
        "# Connect to ChromaDB (using a new collection for lemmatized data)\n",
        "collection_name = \"movie_chunks_lemmatized\"\n",
        "persist_directory = \"/content/drive/MyDrive/chroma_db_lemmatized\"\n",
        "\n",
        "try:\n",
        "    vector_store = Chroma(\n",
        "        collection_name=collection_name,\n",
        "        persist_directory=persist_directory,\n",
        "        embedding_function=embeddings\n",
        "    )\n",
        "    if vector_store._collection.count() == 0:\n",
        "        print(\"Collection is empty. Generating embeddings for lemmatized chunks...\")\n",
        "        # Chroma's add_texts handles embedding internally if an embedding function is provided\n",
        "        vector_store.add_texts(\n",
        "            texts=chunked_texts,\n",
        "            metadatas=chunked_metadatas,\n",
        "            ids=chunked_ids\n",
        "        )\n",
        "        print(f\"Successfully added {len(chunked_texts)} lemmatized chunk embeddings to ChromaDB.\")\n",
        "    else:\n",
        "        print(f\"Using existing lemmatized collection with {vector_store._collection.count()} items.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error with ChromaDB: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "t4d92IU3LlIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fefef50c-9966-4606-a8b5-c0f5c9fa65db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 4: Setting up LLM and Prompt Template...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TinyLlama LLM initialized.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- STEP 4: SETUP LLM AND PROMPT ---\n",
        "\n",
        "print(\"\\nStep 4: Setting up LLM and Prompt Template...\")\n",
        "# Initialize LLM\n",
        "try:\n",
        "    llm_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        model_kwargs={\"temperature\": 0.4, \"max_length\": 512}\n",
        "    )\n",
        "    llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
        "    print(\"TinyLlama LLM initialized.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not load TinyLlama LLM ({e}). Using a placeholder LLM.\")\n",
        "    from langchain_core.language_models import BaseLLM\n",
        "    class MockLLM(BaseLLM):\n",
        "        def _call(self, prompt: str, stop=None) -> str:\n",
        "            if \"specifically for\" in prompt:\n",
        "                movie_title_match = re.search(r\"specifically for '([^']*)'\", prompt)\n",
        "                movie_title = movie_title_match.group(1) if movie_title_match else \"a movie\"\n",
        "                return (f\"Explanation for '{movie_title}': This movie aligns with your query due to its compelling \"\n",
        "                        f\"plot, acclaimed director, and strong performances by its lead actors. It shares thematic \"\n",
        "                        f\"elements and a similar narrative style, making it a great fit for your taste.\")\n",
        "            return f\"Mock LLM response for: {prompt[:200]}...\"\n",
        "        @property\n",
        "        def _llm_type(self) -> str:\n",
        "            return \"mock_llm\"\n",
        "    llm = MockLLM()\n",
        "\n",
        "# Define prompt template\n",
        "prompt_template = \"\"\"Analyze this movie recommendation context:\n",
        "{context}\n",
        "\n",
        "Based on the user's request: \"{query}\", generate a personalized recommendation explaining:\n",
        "1. Genre alignment\n",
        "2. Director/style connections\n",
        "3. Star actor relevance\n",
        "4. Plot similarities\n",
        "Provide a concise explanation for each point.\n",
        "\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    template=prompt_template,\n",
        "    input_variables=[\"context\", \"query\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3jUJN4XqLzEJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- STEP 5: ADVANCED RECOMMENDER CLASS ---\n",
        "\n",
        "class AdvancedRecommender:\n",
        "    def __init__(self, vector_store, llm, prompt_template):\n",
        "        self.store = vector_store\n",
        "        self.llm = llm\n",
        "        self.prompt_template = prompt_template\n",
        "        self.rating_weights = {'IMDB_Rating': 0.6, 'Meta_score': 0.3, 'No_of_Votes': 0.1}\n",
        "\n",
        "    def _hybrid_score(self, movie_metadata):\n",
        "        score = 0\n",
        "        for col, weight in self.rating_weights.items():\n",
        "            if col in movie_metadata and pd.notna(movie_metadata[col]):\n",
        "                if col == 'No_of_Votes':\n",
        "                    normalized_value = torch.log(torch.tensor(movie_metadata[col] + 1)).item() / 10\n",
        "                else:\n",
        "                    normalized_value = movie_metadata[col] / 10\n",
        "                score += normalized_value * weight\n",
        "        return score\n",
        "\n",
        "    def recommend(self, query: str, top_n: int = 5):\n",
        "        # Lemmatize the user's query before searching\n",
        "        lemmatized_query = lemmatize_text(query)\n",
        "        print(f\"Original query: '{query}'\")\n",
        "        print(f\"Lemmatized query: '{lemmatized_query}'\")\n",
        "        print(f\"Searching for chunk candidates...\")\n",
        "\n",
        "        retrieved_chunks = self.store.similarity_search(lemmatized_query, k=top_n * 5)\n",
        "\n",
        "        unique_movies = {}\n",
        "        for chunk in retrieved_chunks:\n",
        "            movie_id = chunk.metadata['movie_id']\n",
        "            if movie_id not in unique_movies:\n",
        "                unique_movies[movie_id] = chunk\n",
        "\n",
        "        sorted_movies = sorted(\n",
        "            unique_movies.values(),\n",
        "            key=lambda doc: self._hybrid_score(doc.metadata),\n",
        "            reverse=True\n",
        "        )[:top_n]\n",
        "\n",
        "        print(f\"Found {len(retrieved_chunks)} relevant chunks, mapping to {len(unique_movies)} unique movies.\")\n",
        "        print(f\"Re-ranked and selected top {len(sorted_movies)} movies.\")\n",
        "\n",
        "        explanations = []\n",
        "        for doc in sorted_movies:\n",
        "            movie_title = doc.metadata.get('Series_Title', 'Unknown Title')\n",
        "            try:\n",
        "                # Use the original, non-lemmatized context for the LLM explanation\n",
        "                full_context = doc.metadata.get('Full_MetaText', doc.page_content)\n",
        "\n",
        "                # Use the original query in the prompt for a natural-sounding explanation\n",
        "                formatted_prompt = self.prompt_template.format(\n",
        "                    context=full_context,\n",
        "                    query=query\n",
        "                )\n",
        "                explanation = self.llm.invoke(formatted_prompt)\n",
        "            except Exception as e:\n",
        "                explanation = f\"Could not generate detailed explanation: {e}\"\n",
        "                print(f\"Warning: Failed to generate explanation for {movie_title}. Error: {e}\")\n",
        "\n",
        "            explanations.append({\n",
        "                'title': movie_title,\n",
        "                'year': doc.metadata.get('Released_Year', 'N/A'),\n",
        "                'rating': doc.metadata.get('IMDB_Rating', 'N/A'),\n",
        "                'explanation': explanation\n",
        "            })\n",
        "\n",
        "        return explanations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awz34LCRa0uy",
        "outputId": "94ecb8cc-1846-405d-b6c0-147874fc2b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 5: Initializing the Final Advanced Recommender...\n",
            "Recommender is ready!\n",
            "\n",
            "--- Testing with a query that benefits from lemmatization ---\n",
            "Original query: 'A movie about a group of friends who go on an adventure'\n",
            "Lemmatized query: 'a movie about a group of friend who go on an adventure'\n",
            "Searching for chunk candidates...\n",
            "Found 15 relevant chunks, mapping to 15 unique movies.\n",
            "Re-ranked and selected top 3 movies.\n",
            "\n",
            "1. 8½ (1963) - IMDB Rating: 8.0\n",
            "   Explanation: Analyze this movie recommendation context:\n",
            "Title: 8½\n",
            "Director: Federico Fellini\n",
            "Genre: Drama\n",
            "Plot: A harried movie director retreats into his memories and fantasies.\n",
            "Stars: Marcello Mastroianni, Anouk Aimée\n",
            "Year: 1963\n",
            "Rating: 8.0\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on an adventure\", generate a personalized recommendation explaining:\n",
            "1. Genre alignment\n",
            "2. Director/style connections\n",
            "3. Star actor relevance\n",
            "4. Plot similarities\n",
            "Provide a concise explanation for each point.\n",
            "\n",
            "Genre Alignment: \n",
            "8½ is a quirky and surreal comedy-drama, with a focus on the eccentricities and dreams of a group of characters. It can be seen as a departure from Federico Fellini's typical style, which is known for its poetic and emotionally resonant moments. However, the director and style connections between this movie and other works by Fellini such as Amarcord (1971) and La Dolce Vita (1960) are clear - the playful and idiosyncratic nature of 8½ can be seen as a continuation of Fellini's themes and aesthetic.\n",
            "\n",
            "Director/Style Connections:\n",
            "Fellini is known for his signature use of surrealism, dreamlike imagery, and intense emotional expression. 8½ follows in this tradition, with its fantastical and unrealistic settings, outrageous dialogue, and dreamlike sequences. It also has a similar style to other films of the era, such as The Apartment (1960) and 1900 (1949). The overall tone and atmosphere of 8½ are also similar to Fellini's earlier work, with its playful and absurdist humor.\n",
            "\n",
            "Star Actor Relevance:\n",
            "Marcello Mastroianni is perhaps the most recognizable star from 8½, with his role as the central character's brother. However, the film also features other notable actors such as Anouk Aimée and Vittorio De Sica. All three actors have worked with Fellini before, contributing to a sense of continuity and familiarity that helps to establish 8½ as a distinctive and beloved work of art.\n",
            "\n",
            "Plot Similarities:\n",
            "There are a few plot similarities between 8½ and other Fellini works. For instance, the film is often described as a \"dream sequence,\" with its surreal and dreamlike moments. It also features an ensemble cast, with each character getting their own moment in the spotlight. However, there are also some unique differences between the two works. For instance, 8½ has a more linear structure, with a clear beginning, middle, and end. It also has a more focused and narratively driven plot, with a central conflict and resolution.\n",
            "\n",
            "Conclusion:\n",
            "In conclusion, 8½ is a quirky and surreal comedy-drama that is both distinctive and beloved. Fellini's use of surrealism, dreamlike imagery, and intense emotional expression is evident in the film, while its similarities to other works by Fellini are also clear. The personalized recommendation provides a concise explanation for why 8½ is a recommended movie for the user's request.\n",
            "\n",
            "2. Lost in Translation (2003) - IMDB Rating: 7.7\n",
            "   Explanation: Analyze this movie recommendation context:\n",
            "Title: Lost in Translation\n",
            "Director: Sofia Coppola\n",
            "Genre: Comedy, Drama\n",
            "Plot: A faded movie star and a neglected young woman form an unlikely bond after crossing paths in Tokyo.\n",
            "Stars: Bill Murray, Scarlett Johansson\n",
            "Year: 2003\n",
            "Rating: 7.7\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on an adventure\", generate a personalized recommendation explaining:\n",
            "1. Genre alignment\n",
            "2. Director/style connections\n",
            "3. Star actor relevance\n",
            "4. Plot similarities\n",
            "Provide a concise explanation for each point.\n",
            "Album Title: Summer Nights\n",
            "Artist: Nat King Cole\n",
            "Track: \"Mona Lisa\"\n",
            "Year: 1956\n",
            "Genre: Pop, Jazz\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on an adventure\", generate a personalized recommendation explaining:\n",
            "1. Genre alignment\n",
            "2. Director/style connections\n",
            "3. Star actor relevance\n",
            "4. Plot similarities\n",
            "Provide a concise explanation for each point.\n",
            "Album Title: The Sound of Music\n",
            "Artist: The von Trapp Family\n",
            "Track: \"Edelweiss\"\n",
            "Year: 1959\n",
            "Genre: Musical, Drama\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on an adventure\", generate a personalized recommendation explaining:\n",
            "1. Genre alignment\n",
            "2. Director/style connections\n",
            "3. Star actor relevance\n",
            "4. Plot similarities\n",
            "Provide a concise explanation for each point.\n",
            "Album Title: The Greatest Showman\n",
            "Artist: Hugh Jackman\n",
            "Track: \"This is Me\"\n",
            "Year: 2017\n",
            "Genre: Musical, Drama\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on an adventure\", generate a personalized recommendation explaining:\n",
            "1. Genre alignment\n",
            "2. Director/style connections\n",
            "3. Star actor relevance\n",
            "4. Plot similarities\n",
            "Provide a concise explanation for each point.\n",
            "Album Title: The Life Ahead\n",
            "Artist: Humphrey Bogart\n",
            "Track: \"The Big Parade\"\n",
            "Year: 1945\n",
            "Genre: Drama\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on an adventure\", generate a personalized recommendation explaining:\n",
            "1. Genre alignment\n",
            "2. Director/style connections\n",
            "3. Star actor relevance\n",
            "4. Plot similarities\n",
            "Provide a concise explanation for each point.\n",
            "Album Title: The Wizard of Oz\n",
            "Artist: Judy Garland\n",
            "Track: \"Over the Rainbow\"\n",
            "Year: 1939\n",
            "Genre: Musical, Drama\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on an adventure\", generate a personalized recommendation explaining:\n",
            "1. Genre alignment\n",
            "2. Director/style connections\n",
            "3. Star actor relevance\n",
            "4. Plot similarities\n",
            "Provide a concise explanation for each point.\n",
            "\n",
            "3. Hable con ella (2002) - IMDB Rating: 7.9\n",
            "   Explanation: Analyze this movie recommendation context:\n",
            "Title: Hable con ella\n",
            "Director: Pedro Almodóvar\n",
            "Genre: Drama, Mystery, Romance\n",
            "Plot: Two men share an odd friendship while they care for two women who are both in deep comas.\n",
            "Stars: Rosario Flores, Javier Cámara\n",
            "Year: 2002\n",
            "Rating: 7.9\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on an adventure\", generate a personalized recommendation explaining:\n",
            "1. Genre alignment\n",
            "2. Director/style connections\n",
            "3. Star actor relevance\n",
            "4. Plot similarities\n",
            "Provide a concise explanation for each point.\n",
            "\n",
            "Example:\n",
            "Director: Martin Scorsese\n",
            "Genre: Crime, Drama, Biography\n",
            "Plot: A gangster's story, told from the perspective of his younger brother, who gets involved in the family business.\n",
            "Stars: Robert De Niro, Al Pacino, James Woods\n",
            "Rating: 9.4\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on a road trip to the Grand Canyon\", generate a personalized recommendation which highlights the movie's setting and theme:\n",
            "1. Setting relevance\n",
            "2. Brand relevance\n",
            "3. Genre alignment\n",
            "4. Directors/style connections\n",
            "Provide a concise explanation for each point.\n",
            "\n",
            "Example:\n",
            "Genre: Drama, Mystery, Thriller\n",
            "Plot: A successful lawyer goes to a remote island to investigate a murder case, but the island's mysterious owner and his family put a wrinkle in her plans.\n",
            "Stars: Jennifer Aniston, Kevin Costner, Kevin Bacon\n",
            "Rating: 8.7\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on a camping trip\", generate a personalized recommendation with a focus on the movie's setting and style:\n",
            "1. Setting relevance\n",
            "2. Brand relevance\n",
            "3. Genre alignment\n",
            "4. Directors/style connections\n",
            "Provide a concise explanation for each point.\n",
            "\n",
            "Example:\n",
            "Genre: Comedy, Romance, Drama\n",
            "Plot: A couple goes on a road trip with their two children, but their plans to escape reality are disrupted by a series of unexpected events.\n",
            "Stars: Julia Roberts, Dennis Quaid, Wentworth Miller\n",
            "Rating: 8.7\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go to a music festival\", generate a personalized recommendation emphasizing the movie's soundtrack:\n",
            "1. Soundtrack relevance\n",
            "2. Genre alignment\n",
            "3. Brand relevance\n",
            "4. Directors/style connections\n",
            "Provide a concise explanation for each point.\n",
            "\n",
            "Example:\n",
            "Genre: Comedy, Music, Drama\n",
            "Plot: Four best friends come to a music festival to celebrate their 21st birthdays, but their idyllic trip is disrupted by a string of unexpected events.\n",
            "Stars: Emma Stone, Jonah Hill, Bill Murray\n",
            "Rating: 9.1\n",
            "\n",
            "Based on the user's request: \"A movie about a group of friends who go on a camping trip and encounter a mystery\", generate a personalized recommendation highlighting the movie's plot:\n",
            "1. Plot relevance\n",
            "2. Genre alignment\n",
            "3. Brand relevance\n",
            "4. Directors/style connections\n",
            "Provide a concise explanation for each point.\n",
            "\n",
            "Example:\n",
            "Genre: Drama, Mystery, Thriller\n",
            "Plot: A group of friends go on a camping trip but encounter a mystery when they discover a hidden cave that leads to a powerful supernatural force.\n",
            "Stars: Jake Gyllenhaal, Michelle Williams, Domhnall Gleeson\n",
            "Rating: 8.7\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- FINAL INITIALIZATION AND TESTING ---\n",
        "print(\"\\nStep 5: Initializing the Final Advanced Recommender...\")\n",
        "recommender = AdvancedRecommender(vector_store, llm, PROMPT)\n",
        "print(\"Recommender is ready!\")\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "print(\"\\n--- Testing with a query that benefits from lemmatization ---\")\n",
        "user_query = \"A movie about a group of friends who go on an adventure\"\n",
        "recommendations = recommender.recommend(user_query, top_n=3)\n",
        "\n",
        "for i, rec in enumerate(recommendations):\n",
        "    print(f\"\\n{i+1}. {rec['title']} ({rec['year']}) - IMDB Rating: {rec['rating']}\")\n",
        "    print(f\"   Explanation: {rec['explanation']}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMRmM395FQ2sLcfthhMpkRm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}